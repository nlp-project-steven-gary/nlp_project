{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import path\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the html file from a file in the curent working directory ('GitHubTopStars_repos.html')\n",
    "def read_GitHub_most_stars(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    "\n",
    "def parse_urls(contents):\n",
    "    soup = BeautifulSoup(contents, 'html.parser')\n",
    "    title = soup.title\n",
    "    orig_text = soup.text\n",
    "    stars = soup.find_all('a', class_= 'v-align-middle')\n",
    "    #  find all the \"hrefs\", which are the trending titles\n",
    "    return(re.findall(r'href=\"(.*?)\"', str(stars)))\n",
    "\n",
    "\n",
    "\n",
    "# Grabs the language and body for each git repo as a dictionary and adds to a list\n",
    "def get_git_info(star_list):\n",
    "    \n",
    "    github_base_url = 'https://github.com'\n",
    "    git_repo_url = []\n",
    "    \n",
    "    for repo in star_list:\n",
    "        git_repo_url.append(github_base_url + repo)\n",
    "\n",
    "    list_of_git_info = []\n",
    "\n",
    "    for repo_address in git_repo_url:\n",
    "        git_repo_url = repo_address \n",
    "        headers = {'User-Agent': 'Codeup Ada Data Science'}\n",
    "        response = get(git_repo_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        language = soup.find('span', class_='lang')\n",
    "\n",
    "#       This adds the part to get to the readme and scrapes the body  \n",
    "        readme_end = '/blob/master/README.md'\n",
    "        readme_url = git_repo_url + readme_end\n",
    "        headers = {'User-Agent': 'Codeup Ada Data Science'}\n",
    "        response = get(readme_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        body = soup.find('article', class_=\"markdown-body entry-content p-3 p-md-6\")\n",
    "\n",
    "#       Combines the language and body to a dictionary, if no language on the repo it is ignored\n",
    "        if language != None:\n",
    "            language = str(language)\n",
    "            list_of_git_info.append({'Language': re.findall(r'>(.*?)<', language)[0],\n",
    "                                     'Body': body})\n",
    "\n",
    "    return list_of_git_info\n",
    "\n",
    "\n",
    "def drop_empty_readmes(repos):\n",
    "    output = []\n",
    "    for repo in repos:\n",
    "        if repo['Body'] != None:\n",
    "            output.append(repo)\n",
    "    return output\n",
    "\n",
    "def find_nunique(string):\n",
    "    words = string.split(\" \")\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)\n",
    "\n",
    "\n",
    "def basic_clean(repo):\n",
    "    repo = re.sub(r'\\s', ' ', repo).lower()\n",
    "    repo = unicodedata.normalize('NFKD', repo)\\\n",
    "        .encode('ascii', 'ignore')\\\n",
    "        .decode('utf-8', 'ignore')\n",
    "    repo = re.sub(r\"[^a-z0-9'\\s]\", '', repo)\n",
    "    return repo\n",
    "\n",
    "\n",
    "def tokenize(repo):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    repo = tokenizer.tokenize(repo, return_str=True)\n",
    "    return repo\n",
    "    \n",
    "\n",
    "def stem(repo):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in repo.split()]\n",
    "    repo_stemmed = ' '.join(stems)\n",
    "    return repo_stemmed\n",
    "\n",
    "\n",
    "def lemmatize(repo):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in repo.split()]\n",
    "    repo_lemmatized = ' '.join(lemmas)\n",
    "    return repo_lemmatized\n",
    "\n",
    "\n",
    "def remove_stopwords(repo, extra_words = [], exclude_words = []):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    [stopword_list.append(word) for word in extra_words if word not in stopword_list]\n",
    "    [stopword_list.remove(word) for word in exclude_words if word in stopword_list]\n",
    "    words = repo.lower().split()\n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "    repo_without_stopwords = ' '.join(filtered_words)\n",
    "    return repo_without_stopwords\n",
    "\n",
    "\n",
    "def prep_repo(dictionary_repo, extra_words = [], exclude_words = []):\n",
    "    cleaned_dict = {\n",
    "    'language': dictionary_repo['Language'],\n",
    "    'original': dictionary_repo['Body'],\n",
    "    'stemmed': stem(dictionary_repo['Body']),\n",
    "    'lemmatized': lemmatize(dictionary_repo['Body']),\n",
    "    'clean': remove_stopwords(basic_clean(dictionary_repo['Body']), extra_words, exclude_words),\n",
    "        }\n",
    "\n",
    "    return cleaned_dict\n",
    "\n",
    "def prepare_repo_data(dictionary_repo, extra_words = [], exclude_words = []):\n",
    "    clean_dict_list = []\n",
    "    \n",
    "    for repo in dictionary_repo:\n",
    "        clean_dict_list.append(prep_repo(repo, extra_words, exclude_words))\n",
    "        \n",
    "    return clean_dict_list\n",
    "\n",
    "def get_df(bulk):\n",
    "    return pd.DataFrame(prepare_repo_data(bulk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can read csv to save time!\n",
    "\n",
    "df = pd.read_csv('git_repo_nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  turn off the web access for now and just read the cached files from the working directory\n",
    "# #  contents = get_GitHub_most_stars()\n",
    "# list_of_html_files = ['GitHubTopStars_repos-page1.html','GitHubTopStars_repos-page2.html',\\\n",
    "#                       'GitHubTopStars_repos-page3.html','GitHubTopStars_repos-page4.html',\\\n",
    "#                       'GitHubTopStars_repos-page5.html','GitHubTopStars_repos-page6.html',\\\n",
    "#                       'GitHubTopStars_repos-page7.html','GitHubTopStars_repos-page8.html',\\\n",
    "#                       'GitHubTopStars_repos-page9.html','GitHubTopStars_repos-page10.html',\\\n",
    "#                       'GitHubTopStars_repos-page11.html','GitHubTopStars_repos-page12.html',\\\n",
    "#                       'GitHubTopStars_repos-page13.html']\n",
    "\n",
    "# star_list = []\n",
    "# for html_file in list_of_html_files:\n",
    "#     contents = read_GitHub_most_stars(html_file)\n",
    "#     next_list = parse_urls(contents)\n",
    "#     star_list = star_list + next_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# github_base_url = 'https://github.com'\n",
    "\n",
    "# git_repo_url = []\n",
    "\n",
    "# for repo in star_list:\n",
    "#     git_repo_url.append(github_base_url + repo)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk = get_git_info(star_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk = drop_empty_readmes(bulk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo in bulk:\n",
    "#     repo['Body'] = repo['Body'].text.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_df(bulk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript     40\n",
       "Python         10\n",
       "C++             8\n",
       "Java            7\n",
       "TypeScript      7\n",
       "Go              7\n",
       "CSS             7\n",
       "Shell           4\n",
       "Vue             3\n",
       "Objective-C     2\n",
       "Ruby            2\n",
       "C               1\n",
       "Dart            1\n",
       "Rust            1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(df['clean'])\n",
    "js_words = ' '.join(df['clean'][df.language == 'JavaScript'])\n",
    "python_words = ' '.join(df['clean'][df.language == 'Python'])\n",
    "cpp_words = ' '.join(df['clean'][df.language == 'C++'])\n",
    "typeScript_words = ' '.join(df['clean'][df.language == 'TypeScript'])\n",
    "go_words = ' '.join(df['clean'][df.language == 'Go'])\n",
    "java_words = ' '.join(df['clean'][df.language == 'Java'])\n",
    "css_words = ' '.join(df['clean'][df.language == 'CSS'])\n",
    "shell_words = ' '.join(df['clean'][df.language == 'Shell'])\n",
    "vue_words = ' '.join(df['clean'][df.language == 'Vue'])\n",
    "ruby_words = ' '.join(df['clean'][df.language == 'Ruby'])\n",
    "objc_words = ' '.join(df['clean'][df.language == 'Objective-C'])\n",
    "dart_words = ' '.join(df['clean'][df.language == 'Dart'])\n",
    "rust_words = ' '.join(df['clean'][df.language == 'Rust'])\n",
    "c_words = ' '.join(df['clean'][df.language == 'C'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freq = pd.Series(all_words.split()).value_counts()\n",
    "js_freq = pd.Series(js_words.split()).value_counts()\n",
    "python_freq = pd.Series(python_words.split()).value_counts()\n",
    "cpp_freq = pd.Series(cpp_words.split()).value_counts()\n",
    "typeScript_freq = pd.Series(typeScript_words.split()).value_counts()\n",
    "go_freq = pd.Series(go_words.split()).value_counts()\n",
    "java_freq = pd.Series(java_words.split()).value_counts()\n",
    "css_freq = pd.Series(css_words.split()).value_counts()\n",
    "shell_freq = pd.Series(shell_words.split()).value_counts()\n",
    "vue_freq = pd.Series(vue_words.split()).value_counts()\n",
    "ruby_freq = pd.Series(ruby_words.split()).value_counts()\n",
    "objc_freq = pd.Series(objc_words.split()).value_counts()\n",
    "dart_freq = pd.Series(dart_words.split()).value_counts()\n",
    "rust_freq = pd.Series(rust_words.split()).value_counts()\n",
    "c_freq = pd.Series(c_words.split()).value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = (pd.concat([all_freq, js_freq, python_freq, cpp_freq,typeScript_freq,\n",
    "                          go_freq, java_freq, css_freq, shell_freq, vue_freq,\n",
    "                          ruby_freq, objc_freq, dart_freq, rust_freq, c_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'js', 'python', 'cpp', 'ts', 'go', 'java',\n",
    "                          'scc', 'shell', 'vue', 'ruby', 'objc', 'dart',\n",
    "                          'rust', 'c'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words in READMEs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>js</th>\n",
       "      <th>python</th>\n",
       "      <th>cpp</th>\n",
       "      <th>ts</th>\n",
       "      <th>go</th>\n",
       "      <th>java</th>\n",
       "      <th>scc</th>\n",
       "      <th>shell</th>\n",
       "      <th>vue</th>\n",
       "      <th>ruby</th>\n",
       "      <th>objc</th>\n",
       "      <th>dart</th>\n",
       "      <th>rust</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>1096</td>\n",
       "      <td>613</td>\n",
       "      <td>204</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>910</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>604</td>\n",
       "      <td>11</td>\n",
       "      <td>586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>545</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          all   js  python  cpp  ts   go  java  scc  shell  vue  ruby  objc  \\\n",
       "use      1096  613     204   21   6   55     9    8    152    9     0    12   \n",
       "go        910   14      14    1   1  871     0    0      1    0     2     0   \n",
       "yes       604   11     586    0   0    0     1    0      0    0     0     2   \n",
       "const     545  542       0    3   0    0     0    0      0    0     0     0   \n",
       "unknown   534    0     534    0   0    0     0    0      0    0     0     0   \n",
       "\n",
       "         dart  rust  c  \n",
       "use         0     0  7  \n",
       "go          0     2  4  \n",
       "yes         0     0  4  \n",
       "const       0     0  0  \n",
       "unknown     0     0  0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.sort_values(by='all', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the length of the README vary by language?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readme_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>26752.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>20854.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Go</th>\n",
       "      <td>18900.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell</th>\n",
       "      <td>14148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Objective-C</th>\n",
       "      <td>8872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>8644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rust</th>\n",
       "      <td>3132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruby</th>\n",
       "      <td>2952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>2746.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>2729.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vue</th>\n",
       "      <td>2403.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dart</th>\n",
       "      <td>1877.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSS</th>\n",
       "      <td>1759.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TypeScript</th>\n",
       "      <td>1208.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             readme_length\n",
       "language                  \n",
       "Python        26752.000000\n",
       "C             20854.000000\n",
       "Go            18900.714286\n",
       "Shell         14148.000000\n",
       "Objective-C    8872.000000\n",
       "JavaScript     8644.000000\n",
       "Rust           3132.000000\n",
       "Ruby           2952.000000\n",
       "C++            2746.875000\n",
       "Java           2729.857143\n",
       "Vue            2403.333333\n",
       "Dart           1877.000000\n",
       "CSS            1759.571429\n",
       "TypeScript     1208.714286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['readme_length'] = df.clean.str.len()\n",
    "df[['language','readme_length']].groupby('language').mean().sort_values('readme_length', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do different languages use a different number of unique words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>1191.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Go</th>\n",
       "      <td>903.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell</th>\n",
       "      <td>700.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Objective-C</th>\n",
       "      <td>481.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>423.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rust</th>\n",
       "      <td>296.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vue</th>\n",
       "      <td>216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruby</th>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>204.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>181.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dart</th>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSS</th>\n",
       "      <td>151.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TypeScript</th>\n",
       "      <td>111.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             unique_words\n",
       "language                 \n",
       "Python        1191.600000\n",
       "C             1182.000000\n",
       "Go             903.142857\n",
       "Shell          700.250000\n",
       "Objective-C    481.000000\n",
       "JavaScript     423.950000\n",
       "Rust           296.000000\n",
       "Vue            216.000000\n",
       "Ruby           214.000000\n",
       "C++            204.375000\n",
       "Java           181.285714\n",
       "Dart           164.000000\n",
       "CSS            151.428571\n",
       "TypeScript     111.285714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['unique_words'] = df.clean.apply(find_nunique)\n",
    "df[['language','unique_words']].groupby('language').mean().sort_values('unique_words', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
